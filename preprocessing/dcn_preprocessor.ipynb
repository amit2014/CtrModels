{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:10:54.942909Z",
     "start_time": "2018-10-15T16:10:53.515721Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:10:54.949904Z",
     "start_time": "2018-10-15T16:10:54.943906Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savePickle(target, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(target, f)\n",
    "        \n",
    "def loadPickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def getLabelDict(labelDataFrame):\n",
    "    label_dict = {}\n",
    "    i = 0\n",
    "    for c in labelDataFrame.columns:\n",
    "        label_dict[i] = c[3:]\n",
    "        label_dict[c[3:]] = i\n",
    "        i = i + 1\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:10:59.349430Z",
     "start_time": "2018-10-15T16:10:54.954901Z"
    }
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"./data/train_all.csv\",low_memory =False)\n",
    "# test = pd.read_csv(\"./data/republish_test.csv\", low_memory =False)\n",
    "# train = pd.read_csv(\"../data/train.csv\",low_memory =False)\n",
    "# test = pd.read_csv(\"../data/test.csv\", low_memory =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:02.001890Z",
     "start_time": "2018-10-15T16:10:59.351391Z"
    }
   },
   "outputs": [],
   "source": [
    "# #测试集，因为确定的是中间两个月的消费数据，可以用前后月的消费数据计算得到。\n",
    "# test.loc[test['2_total_fee'] == '\\\\N','3_total_fee'] = test.loc[test['2_total_fee'] == '\\\\N','1_total_fee']*0.25 + test.loc[test['2_total_fee'] == '\\\\N','4_total_fee']*0.75\n",
    "# test.loc[test['2_total_fee'] == '\\\\N','2_total_fee'] = test.loc[test['2_total_fee'] == '\\\\N','1_total_fee']*0.75 + test.loc[test['2_total_fee'] == '\\\\N','4_total_fee']*0.25\n",
    "# test.loc[test['3_total_fee'] == '\\\\N','3_total_fee'] = test.loc[test['3_total_fee'] == '\\\\N','1_total_fee']*0.2 + test.loc[test['3_total_fee'] == '\\\\N','4_total_fee']*0.75\n",
    "# #训练集， 直接清除所有确实值记录，这很少，不影响结果\n",
    "# train = train[train['2_total_fee'] != '\\\\N']\n",
    "# train = train[train['3_total_fee'] != '\\\\N']\n",
    "# train = train[train['gender'] != '\\\\N']\n",
    "# train = train[train['age'] != '\\\\N'].copy()\n",
    "\n",
    "# train['2_total_fee'] = train['2_total_fee'].apply(float)\n",
    "# train['3_total_fee'] = train['3_total_fee'].apply(float)\n",
    "# train['gender'] = train['gender'].apply(int)\n",
    "# train['age'] = train['age'].apply(int)\n",
    "# test['2_total_fee'] = test['2_total_fee'].apply(float)\n",
    "# test['3_total_fee'] = test['3_total_fee'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:03.841829Z",
     "start_time": "2018-10-15T16:11:02.003877Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "# savePickle(train, \"../data/train.pkl\")\n",
    "# savePickle(test, \"../data/test.pkl\")\n",
    "\n",
    "    \n",
    "train = loadPickle(\"../data/train.pkl\")\n",
    "test = loadPickle(\"../data/test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:05.417928Z",
     "start_time": "2018-10-15T16:11:03.842827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "#将训练集与测试集合并，这样特征处理就可以一致\n",
    "test['current_service'] = -1\n",
    "data = train.append(test)\n",
    "data['2_total_fee'] = data['2_total_fee'].apply(float)\n",
    "data['3_total_fee'] = data['3_total_fee'].apply(float)\n",
    "data['gender'] = data['gender'].apply(int)\n",
    "data['age'] = data['age'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:06.068572Z",
     "start_time": "2018-10-15T16:11:05.419926Z"
    }
   },
   "outputs": [],
   "source": [
    "iseq = np.array(data['1_total_fee'] == data['2_total_fee']).astype(int)\n",
    "isint = np.array(data['1_total_fee']).astype(int) == np.array(data['2_total_fee'])\n",
    "data['same_fee'] = iseq * isint * np.array(data['1_total_fee'])\n",
    "data['min_fee'] = np.min(data[['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee']], axis = 1)\n",
    "data['max_fee'] = np.max(data[['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee']], axis = 1)\n",
    "data['range_fee'] = data['max_fee'] - data['min_fee']\n",
    "data['non_local_trafffic'] = np.array(data['month_traffic']) - np.array(data['local_trafffic_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:49.987487Z",
     "start_time": "2018-10-15T16:11:49.980492Z"
    }
   },
   "outputs": [],
   "source": [
    "category_features = ['complaint_level','contract_type','gender', 'is_mix_service', 'is_promise_low_consume',\n",
    "                     'many_over_bill','net_service','service_type', 'same_fee']\n",
    "floatcontinous_features = ['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee','former_complaint_fee',\n",
    "                           'last_month_traffic',       'local_caller_time', 'local_trafffic_month', \n",
    "                           'month_traffic', 'pay_num', 'service1_caller_time', 'service2_caller_time',\n",
    "                           'min_fee', 'max_fee', 'range_fee',  'non_local_trafffic']\n",
    "intcontinous_features = ['age','contract_time', 'former_complaint_num', 'online_time',  'pay_times']\n",
    "# intcontinous_features = ['contract_time', 'former_complaint_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:52.803880Z",
     "start_time": "2018-10-15T16:11:52.800884Z"
    }
   },
   "outputs": [],
   "source": [
    "# kmeans1 = KMeans(n_clusters=40, random_state=0).fit(data[floatcontinous_features])\n",
    "# kmeans2 = KMeans(n_clusters=12, random_state=0).fit(data[intcontinous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:11:59.682952Z",
     "start_time": "2018-10-15T16:11:53.656396Z"
    }
   },
   "outputs": [],
   "source": [
    "data_encode = pd.DataFrame()\n",
    "for feature in category_features:\n",
    "    data_encode[feature] = np.array(data[feature]).astype(int).astype(np.object)\n",
    "\n",
    "for feature in floatcontinous_features:\n",
    "    v = np.array(data[feature]).astype(np.float32)\n",
    "    v = np.log(v - v.min() + 1) # 平移到 大于1 的正整数空间，然后取对数平滑。\n",
    "    v = v/v.max() #压缩到 0-1 之间。\n",
    "    data_encode[feature] = (v - v.mean())/v.std() # 取值为均值为0，方差为1的样本。\n",
    "    \n",
    "for feature in intcontinous_features:\n",
    "    v = np.array(data[feature]).astype(np.float32)\n",
    "    v = np.log(v - v.min() + 1) # 平移到 大于1 的正整数空间，然后取对数平滑。\n",
    "    v = v/v.max() #压缩到 0-1 之间。\n",
    "    data_encode[feature] = (v - v.mean())/v.std() # 取值为均值为0，方差为1的样本。\n",
    "    \n",
    "# 对于连续变量，进行聚类，进一步挖掘信息。\n",
    "\n",
    "# data_encode['kmeans1'] = np.array(kmeans1.labels_).astype(np.object)\n",
    "# data_encode['kmeans2'] = np.array(kmeans2.labels_).astype(np.object)\n",
    "data_encode = pd.get_dummies(data_encode)\n",
    "data_encode['user_id'] = np.array(data['user_id'])\n",
    "data_encode['current_service'] = np.array(data['current_service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:01.803744Z",
     "start_time": "2018-10-15T16:12:01.800744Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_encode = pd.DataFrame()\n",
    "# for feature in [*category_features, *intcontinous_features]:\n",
    "#     data_encode[feature] = np.array(data[feature]).astype(int).astype(np.object)\n",
    "\n",
    "# for feature in floatcontinous_features:\n",
    "#     v = np.array(data[feature]).astype(np.float32)\n",
    "#     v = np.log(v - v.min() + 1) # 平移到 大于1 的正整数空间，然后取对数平滑。\n",
    "#     v = np.array(v/v.max()*100).astype(int) #转换成0-100的整数\n",
    "#     for i in range(100):\n",
    "#         data_encode['feature_%d'%i] = np.array(v == i).astype(int)\n",
    "    \n",
    "    \n",
    "\n",
    "# data_encode = pd.get_dummies(data_encode)\n",
    "# data_encode['user_id'] = np.array(data['user_id'])\n",
    "# data_encode['current_service'] = np.array(data['current_service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:02.003629Z",
     "start_time": "2018-10-15T16:12:01.996633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943986, 483)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:02.164536Z",
     "start_time": "2018-10-15T16:12:02.162537Z"
    }
   },
   "outputs": [],
   "source": [
    "# def print_stats(tdf):\n",
    "#     dct = Counter(tdf)\n",
    "#     cn = len(tdf)\n",
    "#     for key in dct.keys():\n",
    "#         print(key, round(dct[key]/cn, 3))\n",
    "#     print(cn, end = \"\\n\\n\")\n",
    "    \n",
    "# odf = train['current_service']\n",
    "# print_stats(odf)\n",
    "# # tdf = train[train['former_complaint_fee'] > 0][train['former_complaint_fee'] < 100]['current_service']\n",
    "# tdf = train[train['3_total_fee'] < 0 ]['current_service']\n",
    "# print_stats(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:04.669119Z",
     "start_time": "2018-10-15T16:12:02.344434Z"
    }
   },
   "outputs": [],
   "source": [
    "#test data\n",
    "testData = data_encode[data_encode.current_service == -1]\n",
    "featureTest = testData.drop(['current_service', 'user_id'], axis = 1)\n",
    "TestResult = testData[['user_id']].copy()\n",
    "\n",
    "#train data \n",
    "trainData = data_encode[data_encode.current_service != -1]\n",
    "feature = trainData.drop(['current_service', 'user_id'],axis = 1)\n",
    "\n",
    "# label encode\n",
    "label = pd.DataFrame()\n",
    "label['cs'] = np.array(trainData['current_service']).astype(np.int).astype(np.object)\n",
    "label = pd.get_dummies(label)\n",
    "label_dict = getLabelDict(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:05.372704Z",
     "start_time": "2018-10-15T16:12:04.671118Z"
    }
   },
   "outputs": [],
   "source": [
    "continous_col = [*floatcontinous_features, *intcontinous_features]\n",
    "train_x_continuous = feature[continous_col]\n",
    "train_x_onehot = feature.drop(continous_col, axis = 1)\n",
    "test_x_continous = featureTest[continous_col]\n",
    "test_x_onehot = featureTest.drop(continous_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:13.562030Z",
     "start_time": "2018-10-15T16:12:05.375703Z"
    }
   },
   "outputs": [],
   "source": [
    "savePickle(train_x_continuous, \"../data/normaldata/train_x_continuous.pkl\")\n",
    "savePickle(train_x_onehot, \"../data/normaldata/train_x_onehot.pkl\")\n",
    "savePickle(test_x_continous, \"../data/normaldata/test_x_continous.pkl\")\n",
    "savePickle(test_x_onehot, \"../data/normaldata/test_x_onehot.pkl\")\n",
    "savePickle(feature, \"../data/normaldata/train_x.pkl\")\n",
    "savePickle(featureTest, \"../data/normaldata/test_x.pkl\")\n",
    "savePickle(label, \"../data/normaldata/train_y.pkl\")\n",
    "savePickle(label_dict, \"../data/normaldata/label_dict.pkl\")\n",
    "savePickle(TestResult, \"../data/normaldata/TestResult.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:12:13.569027Z",
     "start_time": "2018-10-15T16:12:13.564029Z"
    }
   },
   "outputs": [],
   "source": [
    "# savePickle(feature, \"./data/onehot/train_x.pkl\")\n",
    "# savePickle(featureTest, \"./data/onehot/test_x.pkl\")\n",
    "# savePickle(label, \"./data/onehot/train_y.pkl\")\n",
    "# savePickle(label_dict, \"./data/onehot/label_dict.pkl\")\n",
    "# savePickle(TestResult, \"./data/onehot/TestResult.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
