{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:19.545355Z",
     "start_time": "2018-10-15T16:21:17.215617Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "from collections import Counter\n",
    "def savePickle(target, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(target, f)\n",
    "def loadPickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 1_total_fee array([ 0.39827125,  0.39316978,  0.39571121])\n",
    " - 2_total_fee _array([ 0.34979964,  0.35166863,  0.35014922])\n",
    " - 3_total_fee array([ 0.34979964,  0.35166863,  0.35014922])\n",
    " - 4_total_fee  array([ 0.3525123 ,  0.35381964,  0.35444017])\n",
    " - 1234 array([ 0.56280605,  0.56499034,  0.56352438])\n",
    " c =  array([ 0.29369751,  0.29296579,  0.29410951])\n",
    " ---------------------------------------------------\n",
    " ####  total fee\n",
    "  - 1234 0.5604\n",
    "  - 1234 + 1/2 0.5630\n",
    "  - 1234 +1/2 1/3 0.5648\n",
    "  - 1234 + 1/2+1/3+2/4 0.5651\n",
    "  - 1234 + 1/2 1/3 1/4 2/3 2/4 0.5662\n",
    "  - 1234 + 1/2 1/3 1/4 2/3 2/4 1/234 0.5665\n",
    "  - 1234 + 1/2 1/3 1/4 2/3 2/4 3/4 1/234 0.5674\n",
    "  \n",
    "#### traffic\n",
    "  - fee + local 0.5994\n",
    "  - fee + local + last 0.7095\n",
    "  - fee + local _ last + month 0.7472\n",
    "  - fee + local _ last + month +  last/month 0.7476\n",
    "  - fee + local _ last + month +  last/month local/month 0.7493\n",
    "  \n",
    "#### call\n",
    "  -  fee + traffic + local 0.7519\n",
    "  -  fee + traffic + local + service1 0.7850\n",
    "  -  fee + traffic + local + service1 + service2  0.8160\n",
    "  -  fee + traffic + local + service1 + service2 + s2/local 0.8162\n",
    "  \n",
    "#### nature\n",
    "  - fee + traffic + call + age  0.8184\n",
    "  - fee + traffic + call + age + gender 0.8189\n",
    "  \n",
    "#### statistics\n",
    "  - fee + traffic + call + age + onlinetime 0.0.8280\n",
    "  - fee + traffic + call + age + onlinetime + service_type 0.8352\n",
    "  - fee + traffic + call + age + onlinetime + service_type + is_mix_type 0.8362\n",
    "  - ... +  many_over_bill 0.8443\n",
    "  - ... +  contract_type 0.8496\n",
    "  - ... + contract_time 0.8683\n",
    "  - ... + is_promise_low_consume 0.8689\n",
    "  - ... + pay_times 0.8690\n",
    "  - ... + pay_num 0.8693\n",
    "#### cross feature\n",
    "  - ... + traffic/fee 0.8699\n",
    "  - ... + traffic/call 0.8701\n",
    "  - ... 8839， 0.8843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:19.552527Z",
     "start_time": "2018-10-15T16:21:19.545355Z"
    }
   },
   "outputs": [],
   "source": [
    "def square_f1_score(y_true, y_pred):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    samples = len(y_true)\n",
    "    classes = int(len(y_pred)/samples)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(0, classes):\n",
    "        df['c_%d'%i] =  y_pred[samples * i: samples*(i+1)]\n",
    "    pred = np.argmax(np.array(df), axis = 1)\n",
    "    score = np.square(f1_score(y_true, pred, average = 'macro'))\n",
    "    return 'square_f1_score', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:19.565507Z",
     "start_time": "2018-10-15T16:21:19.555513Z"
    }
   },
   "outputs": [],
   "source": [
    "def getfeeDistance(fee1, fee2):\n",
    "    #计算规范化之后，1_totol_fee 和 2_total_fee 组成的二维图中，样本离对角线的距离。\n",
    "    n1_fee = np.log(fee1 + 1)\n",
    "    n1_fee = n1_fee/np.max(n1_fee)\n",
    "    n2_fee = np.log(fee2 + 1)\n",
    "    n2_fee = n1_fee/np.max(n2_fee)\n",
    "    d_fee_1_2 = abs(n1_fee - n2_fee)/1.4142\n",
    "    d_fee12_o = np.sqrt(np.power(n1_fee, 2) + np.power(n2_fee, 2))\n",
    "    return d_fee_1_2, d_fee12_o\n",
    "\n",
    "def normalize(feature, log = True, percent = -1):\n",
    "    c = np.array(feature)\n",
    "    if 0 < percent < 100:\n",
    "        top = np.percentile(c, 100 - percent)\n",
    "        bottom = np.percentile(c, percent)\n",
    "        maxv = top + 2*(top - bottom)\n",
    "        minv = bottom - 2*(top - bottom)\n",
    "        c = np.array([maxv if v > maxv else v for v in c ])\n",
    "        c = np.array([minv if v < minv else v for v in c ])\n",
    "    if log:\n",
    "        c = np.log(c + 1)\n",
    "    c = c/np.max(c)\n",
    "    return c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:28.702927Z",
     "start_time": "2018-10-15T16:21:19.567507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:86: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enc = OneHotEncoder()\n",
    "train = loadPickle(\"../data/train.pkl\")\n",
    "test = loadPickle(\"../data/test.pkl\")\n",
    "test['2_total_fee'] = test['2_total_fee'].astype(np.float32)\n",
    "test['3_total_fee'] = test['3_total_fee'].astype(np.float32)\n",
    "test['3_total_fee'] = test['3_total_fee'].astype(np.float32)\n",
    "categoryes = sorted(train['current_service'].unique())\n",
    "label_dict = {}\n",
    "for i in range(len(categoryes)):\n",
    "    label_dict[categoryes[i]] = i\n",
    "    label_dict[i] = categoryes[i]\n",
    "\n",
    "test['current_service'] = -1\n",
    "train['current_service'] = np.array(train['current_service'].apply(lambda x:label_dict[x]))\n",
    "train = train.append(test)\n",
    "features = train[['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee']].copy()\n",
    "features['1_2_total_fee_n'] = np.array(features['1_total_fee'])/np.array(features['2_total_fee'])\n",
    "features['1_3_total_fee_n'] = np.array(features['1_total_fee'])/np.array(features['3_total_fee'])\n",
    "features['2_4_total_fee_n'] = np.array(features['2_total_fee'])/np.array(features['4_total_fee'])\n",
    "features['2_3_total_fee_n'] = np.array(features['2_total_fee'])/np.array(features['3_total_fee'])\n",
    "features['3_4_total_fee_n'] = np.array(features['3_total_fee'])/np.array(features['4_total_fee'])\n",
    "features.loc[features['2_total_fee'] == 0, '1_2_total_fee_n'] =  -1\n",
    "features.loc[features['3_total_fee'] == 0, '1_3_total_fee_n'] =  -1\n",
    "features.loc[features['4_total_fee'] == 0, '2_4_total_fee_n'] =  -1\n",
    "features.loc[features['3_total_fee'] == 0, '2_3_total_fee_n'] =  -1\n",
    "features.loc[features['4_total_fee'] == 0, '3_4_total_fee_n'] =  -1\n",
    "features['max_fee'] = np.max(np.array(features[['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee']]),axis = 1)\n",
    "features['min_fee'] = np.min(np.array(features[['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee']]),axis = 1)\n",
    "features['same_fee12'] = np.array(np.array(features['1_total_fee'])== np.array(features['2_total_fee'])).astype(int)*np.array(features['1_total_fee'])\n",
    "features['fee_span'] = features['max_fee'] - features['min_fee']\n",
    "features['same_fee_service4'] = np.array(np.array(features['1_total_fee'])== np.array(features['2_total_fee'])).astype(int)*np.array(train['service_type'] == 4).astype(np.int8)\n",
    "# traficc\n",
    "features['local_trafffic_month'] = np.array(train['local_trafffic_month']).astype(np.float32)\n",
    "features['last_month_traffic'] = np.array(train['last_month_traffic']).astype(np.float32)\n",
    "features['month_traffic'] = normalize(train['month_traffic'], log = True, percent = 25).astype(np.float32)\n",
    "features['r_last_month_traffic'] = np.array(train['last_month_traffic'])/np.array(train['month_traffic'])\n",
    "features['r_local_month_traffic'] = np.array(train['local_trafffic_month'])/np.array(train['month_traffic'])\n",
    "features.loc[features['month_traffic'] == 0, 'r_last_month_traffic'] =  -1\n",
    "features.loc[features['month_traffic'] == 0, 'r_local_month_traffic'] =  -1\n",
    "features['r_last_month_traffic'] = normalize(features['r_last_month_traffic'], log = True, percent = 25).astype(np.float32)\n",
    "features['r_local_month_traffic'] = normalize(features['r_local_month_traffic'], log = True, percent = 25).astype(np.float32)\n",
    "features['non_local_trafffic_month'] = (np.array(train['month_traffic']) - np.array(train['local_trafffic_month'])).astype(np.float32)\n",
    "\n",
    "#call\n",
    "features['local_caller_time'] = np.array(train['local_caller_time']).astype(np.float32)\n",
    "features['service1_caller_time'] = np.array(train['service1_caller_time']).astype(np.float32)\n",
    "features['service2_caller_time'] = np.array(train['service2_caller_time']).astype(np.float32)\n",
    "features['s2_local_caller_time'] = np.array(train['service2_caller_time'])/np.array(train['local_caller_time'])\n",
    "features['s1_s2_caller_time'] = np.array(train['service1_caller_time'])/np.array(train['service2_caller_time'])\n",
    "features.loc[features['local_caller_time'] == 0, 's2_local_caller_time'] =  -1\n",
    "features.loc[features['service2_caller_time'] == 0, 's1_s2_caller_time'] =  -1\n",
    "features['s2_local_caller_time'] = normalize(features['s2_local_caller_time'], log = True, percent = 25)\n",
    "features['s1_s2_caller_time'] = normalize(features['s1_s2_caller_time'], log = True, percent = 25)\n",
    "#nature\n",
    "features['age'] = train['age']\n",
    "features['gender0'] = np.array(train['gender'] == 0).astype(np.int8)\n",
    "features['gender1'] = np.array(train['gender'] == 1).astype(np.int8)\n",
    "features['gender2'] = np.array(train['gender'] == 2).astype(np.int8)\n",
    "\n",
    "#other\n",
    "features['online_time'] = train['online_time']\n",
    "features['service_type4'] = np.array(train['service_type'] == 4).astype(np.int8)\n",
    "features['service_type1'] = np.array(train['service_type'] == 1).astype(np.int8)\n",
    "features['is_mix_service'] = train['is_mix_service']\n",
    "features['many_over_bill'] = train['many_over_bill']\n",
    "features['contract_type0'] = np.array(train['contract_type'] == 0).astype(np.int8)\n",
    "features['contract_type1'] = np.array(train['contract_type'] == 1).astype(np.int8)\n",
    "features['contract_type2'] = np.array(train['contract_type'] == 2).astype(np.int8)\n",
    "features['contract_type3'] = np.array(train['contract_type'] == 3).astype(np.int8)\n",
    "features['contract_type6'] = np.array(train['contract_type'] == 6).astype(np.int8)\n",
    "features['contract_type7'] = np.array(train['contract_type'] == 7).astype(np.int8)\n",
    "features['contract_type8'] = np.array(train['contract_type'] == 8).astype(np.int8)\n",
    "features['contract_type9'] = np.array(train['contract_type'] == 9).astype(np.int8)\n",
    "features['contract_type12'] = np.array(train['contract_type'] == 12).astype(np.int8)\n",
    "\n",
    "for t in sorted(train['contract_time'].unique()):\n",
    "    features['contract_time_%d'%t] = np.array(train['contract_time'] == t).astype(np.int8)\n",
    "features['is_promise_low_consume'] = np.array(train['is_promise_low_consume']).astype(np.int8)\n",
    "# for t in sorted(train['net_service'].unique()):\n",
    "#     features['net_service_%d'%t] = np.array(train['net_service'] == t).astype(int) not good\n",
    "features['pay_times'] = np.array(train['pay_times']).astype(np.int32)\n",
    "features['pay_num'] = np.array(train['pay_num']).astype(np.float32)\n",
    "\n",
    "# cross\n",
    "features['traffic_fee'] = normalize(train['month_traffic'])/normalize(train['1_total_fee'])\n",
    "features.loc[features['1_total_fee'] == 0, 'traffic_fee'] =  -1\n",
    "features['traffic_fee'] = normalize(features['traffic_fee'], log = False, percent = 25).astype(np.float32)\n",
    "\n",
    "#计算规范化之后，1_totol_fee 和 2_total_fee 组成的二维图中，样本离对角线的距离。\n",
    "features['d_fee_1_2'], features['d_fee12_o'] = getfeeDistance(features['1_total_fee'], features['2_total_fee'])\n",
    "features['d_fee_2_3'], features['d_fee23_o'] = getfeeDistance(features['2_total_fee'], features['3_total_fee'])\n",
    "features['d_fee_3_4'], features['d_fee34_o'] = getfeeDistance(features['3_total_fee'], features['4_total_fee'])\n",
    "\n",
    "#计算相等金额离散化值\n",
    "\n",
    "c1 = normalize(features['local_trafffic_month'])\n",
    "c2 = normalize(features['month_traffic'])\n",
    "c2 = np.power(c2,0.0625)\n",
    "features['traffic_magic'] = c1 - c2\n",
    "\n",
    "c1 = normalize(features['local_caller_time'])\n",
    "c2 = normalize(features['service1_caller_time'])\n",
    "features['d_local_service1'] = c1 - c2\n",
    "features['d_local_service2'] =  c2 + c2\n",
    "\n",
    "\n",
    "\n",
    "# userid \n",
    "features['user_id'] = train['user_id']\n",
    "features['current_service'] = train['current_service']\n",
    "\n",
    "features = features.fillna(-1)\n",
    "train = features[features.current_service >= 0].copy()\n",
    "test = features[features.current_service < 0].drop(['current_service'], axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:42.058471Z",
     "start_time": "2018-10-15T16:21:29.733806Z"
    }
   },
   "outputs": [],
   "source": [
    "du = train[train.duplicated(keep = False)]\n",
    "# du = du[du['current_service'] != 3]\n",
    "# du = du[du['current_service'] != 4]\n",
    "train_x = train.drop_duplicates(keep = False).drop(['current_service', 'user_id'], axis = 1)\n",
    "train_y = np.array(train.drop_duplicates(keep = False)['current_service'])\n",
    "du_x = du.drop(['current_service', 'user_id'], axis = 1)\n",
    "du_y = np.array(du['current_service'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "train_x = coo_matrix(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(train_x, \"../data/fedata/train_x0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(train_x.tolil(), \"../data/fedata/train_x1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:42.622855Z",
     "start_time": "2018-10-15T16:21:42.058471Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, eval_x, train_y, eval_y = train_test_split(train_x, train_y, test_size = 0.3, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = np.vstack([train_x, du_x])\n",
    "# train_y = np.hstack([train_y, du_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:45.017726Z",
     "start_time": "2018-10-15T16:21:42.622855Z"
    }
   },
   "outputs": [],
   "source": [
    "# def downSample(train_x, train_y, class_label, frac):\n",
    "#     trainData = pd.DataFrame(train_x)\n",
    "#     trainData['y'] = np.array(train_y)\n",
    "#     c = trainData[trainData['y'] == class_label]\n",
    "#     c = c.sample(frac = frac)\n",
    "#     trainData = trainData[trainData['y'] != class_label].copy()\n",
    "#     trainData = trainData.append(c)\n",
    "#     return trainData.drop(['y'], axis = 1), np.array(trainData['y'])\n",
    "# print(\"before:\", train_x.shape)\n",
    "# # train_x, train_y = downSample(train_x, train_y, 3, 0.4)\n",
    "# # train_x, train_y = downSample(train_x, train_y, 4, 0.5)\n",
    "# # train_x, train_y = downSample(train_x, train_y, 0, 0.85)\n",
    "# print(\"after:\", train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:45.024733Z",
     "start_time": "2018-10-15T16:21:45.019724Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_y = np.array(train_y == 10).astype(int)\n",
    "# eval_y = np.array(eval_y == 10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T16:21:45.037713Z",
     "start_time": "2018-10-15T16:21:45.026720Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-15T16:21:24.420Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.59558\tvalid_0's square_f1_score: 0.635843\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-e3ef09b8c451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mnum_leaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m58\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0471\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9375\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         subsample_for_bin = 200000, subsample_freq = 1,verbosity = 0, verbose_eval = 100)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_f1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    673\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    467\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1523\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weight_dict = {0:1, 1:1, 2:1, 3:0.7, 4:0.9, 5:1, 6:1, 7:2, 8:2, 9:2, 10:2}\n",
    "lgbm = lgb.LGBMClassifier(objective = \"multiclass\", boosting_type =  'gbdt', class_weight = None,\n",
    "                          colsample_bytree = 0.625, importance_type = 'split', learning_rate = 0.2, max_depth = 9,\n",
    "                         min_child_samples = 133, min_child_weight = 2, min_split_gain = 0.1, n_estimators = 1650, n_jobs = -1,\n",
    "                         num_leaves = 58, random_state = 10, reg_alpha = 0.0005, reg_lambda = 0.0471,  subsample = 0.9375,\n",
    "                        subsample_for_bin = 200000, subsample_freq = 1,verbosity = 0, verbose_eval = 100)\n",
    "lgbm.fit(train_x, train_y, eval_set = (eval_x, eval_y), eval_metric = square_f1_score, early_stopping_rounds = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T07:59:36.778885Z",
     "start_time": "2018-10-14T07:59:34.715413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9129623427054058 0.8335002391981428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred = lgbm.predict(eval_x)\n",
    "score = f1_score(eval_y, pred, average = 'macro')\n",
    "print(score, np.square(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T00:34:08.641087Z",
     "start_time": "2018-10-14T00:34:08.636090Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "test_feature = test.drop(['user_id'], axis = 1)\n",
    "TestResult = test[['user_id']].copy()\n",
    "TestResult['predict']  = lgbm.predict(test_feature)\n",
    "TestResult['predict'] = TestResult['predict'].apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestResult.to_csv(\"../lgb8404.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195906\n",
      "195638\n",
      "198897\n"
     ]
    }
   ],
   "source": [
    "complex_pred = pd.read_csv(\"../lgb_xgb_complex_co1008.csv\")\n",
    "xgb_pred = pd.read_csv(\"../xgb_ox_2799743984766_0.8280.csv\")\n",
    "print(np.sum(TestResult.predict == complex_pred.predict))\n",
    "print(np.sum(TestResult.predict == xgb_pred.predict))\n",
    "print(np.sum(complex_pred.predict == xgb_pred.predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-4ca25a2ad336>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-4ca25a2ad336>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    weight none\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "add\n",
    "----------------------------------\n",
    "195934\n",
    "195683\n",
    "198897\n",
    "0.9127246979187341 0.8330663741908444\n",
    "add fee span\n",
    "----------------------------------\n",
    "195934\n",
    "195683\n",
    "198897\n",
    "0.9130197310738052 0.8336050293300835\n",
    "remove downsample\n",
    "---------------------------------------\n",
    "195733\n",
    "195509\n",
    "198897\n",
    "#no remove//\n",
    "0.9122774781828479 0.8322501971996565\n",
    "----------------------------------------\n",
    "195633\n",
    "195403\n",
    "198897\n",
    "weight none\n",
    "--------------------------\n",
    "195462\n",
    "195245\n",
    "198897\n",
    "\n",
    "\n",
    "remove useless contract_time\n",
    "---------------------------------\n",
    "0.9126578740311804 0.832944395031114\n",
    "195874\n",
    "195680\n",
    "198897\n",
    "after fee-e remove du\n",
    "_________________________________________\n",
    "0.9125542444811867 0.8327552491206295\n",
    "195782\n",
    "195574\n",
    "198897\n",
    "before fee-e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T06:34:35.337726Z",
     "start_time": "2018-10-14T06:34:35.275761Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.936     0.944     0.940     40270\n",
      "          1      0.906     0.895     0.901     22125\n",
      "          2      0.978     0.954     0.966     10030\n",
      "          3      0.999     0.995     0.997     85873\n",
      "          4      0.995     0.997     0.996     11329\n",
      "          5      0.948     0.985     0.967      6665\n",
      "          6      0.949     0.966     0.957      6114\n",
      "          7      0.819     0.877     0.847      8738\n",
      "          8      0.810     0.813     0.811      9679\n",
      "          9      0.863     0.858     0.861     15940\n",
      "         10      0.829     0.767     0.797      6433\n",
      "\n",
      "avg / total      0.944     0.944     0.944    223196\n",
      "\n",
      "{89950166: 0, 0: 89950166, 89950167: 1, 1: 89950167, 89950168: 2, 2: 89950168, 90063345: 3, 3: 90063345, 90109916: 4, 4: 90109916, 90155946: 5, 5: 90155946, 99999825: 6, 6: 99999825, 99999826: 7, 7: 99999826, 99999827: 8, 8: 99999827, 99999828: 9, 9: 99999828, 99999830: 10, 10: 99999830}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(eval_y, pred, digits = 3))\n",
    "print(label_dict, end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-146-4b7186522729>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-146-4b7186522729>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    precision    recall  f1-score   support\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0      0.938     0.943     0.941     40270\n",
    "          1      0.905     0.895     0.900     22125\n",
    "          2      0.978     0.955     0.966     10030\n",
    "          3      0.999     0.995     0.997     85873\n",
    "          4      0.995     0.997     0.996     11329\n",
    "          5      0.948     0.985     0.966      6665\n",
    "          6      0.949     0.964     0.956      6114\n",
    "          7      0.820     0.881     0.849      8738\n",
    "          8      0.806     0.811     0.808      9679\n",
    "          9      0.863     0.859     0.861     15940\n",
    "         10      0.828     0.769     0.797      6433\n",
    "\n",
    "avg / total      0.945     0.944     0.944    223196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T04:31:17.526255Z",
     "start_time": "2018-10-14T04:31:17.514260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('contract_type8', 0),\n",
       " ('contract_time_5', 0),\n",
       " ('contract_time_6', 0),\n",
       " ('contract_time_9', 0),\n",
       " ('contract_time_14', 0),\n",
       " ('contract_time_21', 0),\n",
       " ('contract_time_22', 0),\n",
       " ('contract_time_27', 0),\n",
       " ('contract_time_28', 0),\n",
       " ('contract_time_29', 0),\n",
       " ('contract_time_31', 0),\n",
       " ('contract_time_32', 0),\n",
       " ('contract_time_33', 0),\n",
       " ('contract_time_37', 0),\n",
       " ('contract_time_39', 0),\n",
       " ('contract_time_40', 0),\n",
       " ('contract_time_43', 0),\n",
       " ('contract_time_45', 0),\n",
       " ('contract_time_48', 0),\n",
       " ('contract_time_50', 0),\n",
       " ('contract_time_51', 0),\n",
       " ('contract_time_52', 0),\n",
       " ('same_fee_service4', 11),\n",
       " ('contract_time_19', 39),\n",
       " ('contract_time_-1', 66),\n",
       " ('contract_time_8', 66),\n",
       " ('contract_time_7', 72),\n",
       " ('contract_time_20', 72),\n",
       " ('contract_time_16', 82),\n",
       " ('contract_time_11', 86),\n",
       " ('contract_time_10', 96),\n",
       " ('gender1', 100),\n",
       " ('contract_time_25', 109),\n",
       " ('contract_time_34', 125),\n",
       " ('service_type1', 135),\n",
       " ('contract_time_26', 144),\n",
       " ('contract_time_17', 146),\n",
       " ('contract_time_23', 159),\n",
       " ('contract_time_35', 163),\n",
       " ('contract_time_30', 178),\n",
       " ('contract_time_15', 180),\n",
       " ('contract_time_18', 180),\n",
       " ('contract_type7', 217),\n",
       " ('contract_time_13', 230),\n",
       " ('contract_time_0', 256),\n",
       " ('contract_type6', 289),\n",
       " ('gender2', 299),\n",
       " ('service_type4', 357),\n",
       " ('contract_type2', 376),\n",
       " ('is_mix_service', 416),\n",
       " ('contract_time_24', 436),\n",
       " ('contract_type0', 442),\n",
       " ('contract_time_12', 483),\n",
       " ('gender0', 498),\n",
       " ('contract_type1', 537),\n",
       " ('contract_time_36', 557),\n",
       " ('is_promise_low_consume', 562),\n",
       " ('contract_type9', 764),\n",
       " ('contract_type3', 904),\n",
       " ('contract_type12', 958),\n",
       " ('d_fee23_o', 1332),\n",
       " ('many_over_bill', 1525),\n",
       " ('d_fee34_o', 1553),\n",
       " ('d_local_service2', 1717),\n",
       " ('d_fee12_o', 1836),\n",
       " ('same_fee12', 2047),\n",
       " ('pay_times', 2869),\n",
       " ('d_fee_2_3', 3496),\n",
       " ('s1_s2_caller_time', 4015),\n",
       " ('d_fee_3_4', 4034),\n",
       " ('service1_caller_time', 4315),\n",
       " ('d_fee_1_2', 4333),\n",
       " ('r_last_month_traffic', 4557),\n",
       " ('s2_local_caller_time', 8238),\n",
       " ('r_local_month_traffic', 8456),\n",
       " ('local_caller_time', 8543),\n",
       " ('month_traffic', 8890),\n",
       " ('local_trafffic_month', 8951),\n",
       " ('2_total_fee', 9035),\n",
       " ('traffic_magic', 9048),\n",
       " ('max_fee', 9218),\n",
       " ('3_total_fee', 10431),\n",
       " ('age', 10461),\n",
       " ('last_month_traffic', 10587),\n",
       " ('1_3_total_fee_n', 10804),\n",
       " ('2_3_total_fee_n', 10926),\n",
       " ('d_local_service1', 10934),\n",
       " ('2_4_total_fee_n', 11485),\n",
       " ('4_total_fee', 11496),\n",
       " ('1_2_total_fee_n', 11546),\n",
       " ('3_4_total_fee_n', 11776),\n",
       " ('pay_num', 11834),\n",
       " ('1_total_fee', 11930),\n",
       " ('non_local_trafffic_month', 12323),\n",
       " ('min_fee', 14034),\n",
       " ('traffic_fee', 14250),\n",
       " ('service2_caller_time', 16461),\n",
       " ('online_time', 16705)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict(zip(du_x.columns, lgbm.feature_importances_)).items(), key = lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.178\n",
      "1 0.099\n",
      "2 0.045\n",
      "3 0.387\n",
      "4 0.051\n",
      "5 0.03\n",
      "6 0.027\n",
      "7 0.039\n",
      "8 0.044\n",
      "9 0.071\n",
      "10 0.028\n",
      "520790\n",
      "\n",
      "89950166 0.084\n",
      "89950167 0.101\n",
      "89950168 0.019\n",
      "90063345 0.58\n",
      "90109916 0.05\n",
      "90155946 0.035\n",
      "99999825 0.015\n",
      "99999826 0.026\n",
      "99999827 0.022\n",
      "99999828 0.045\n",
      "99999830 0.023\n",
      "200000\n",
      "\n",
      "89950166 0.085\n",
      "89950167 0.102\n",
      "89950168 0.019\n",
      "90063345 0.58\n",
      "90109916 0.05\n",
      "90155946 0.035\n",
      "99999825 0.016\n",
      "99999826 0.028\n",
      "99999827 0.021\n",
      "99999828 0.044\n",
      "99999830 0.021\n",
      "200000\n",
      "\n",
      "89950166 0.086\n",
      "89950167 0.102\n",
      "89950168 0.019\n",
      "90063345 0.58\n",
      "90109916 0.05\n",
      "90155946 0.035\n",
      "99999825 0.016\n",
      "99999826 0.028\n",
      "99999827 0.021\n",
      "99999828 0.044\n",
      "99999830 0.02\n",
      "200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_stats(tdf):\n",
    "    dct = Counter(tdf)\n",
    "    cn = len(tdf)\n",
    "    for key in sorted(dct.keys()):\n",
    "        print(key, round(dct[key]/cn, 3))\n",
    "    print(cn, end = \"\\n\\n\")\n",
    "print_stats(train_y)\n",
    "print_stats(TestResult.predict)\n",
    "print_stats(xgb_pred.predict)\n",
    "print_stats(complex_pred.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
