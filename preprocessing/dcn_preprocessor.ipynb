{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savePickle(target, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(target, f)\n",
    "        \n",
    "def loadPickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def getLabelDict(labelDataFrame):\n",
    "    label_dict = {}\n",
    "    i = 0\n",
    "    for c in labelDataFrame.columns:\n",
    "        label_dict[i] = c[3:]\n",
    "        label_dict[c[3:]] = i\n",
    "        i = i + 1\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train_all.csv\",low_memory =False)\n",
    "test = pd.read_csv(\"./data/republish_test.csv\", low_memory =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集，因为确定的是中间两个月的消费数据，可以用前后月的消费数据计算得到。\n",
    "test.loc[test['2_total_fee'] == '\\\\N','3_total_fee'] = test.loc[test['2_total_fee'] == '\\\\N','1_total_fee']*0.25 + test.loc[test['2_total_fee'] == '\\\\N','4_total_fee']*0.75\n",
    "test.loc[test['2_total_fee'] == '\\\\N','2_total_fee'] = test.loc[test['2_total_fee'] == '\\\\N','1_total_fee']*0.75 + test.loc[test['2_total_fee'] == '\\\\N','4_total_fee']*0.25\n",
    "test.loc[test['3_total_fee'] == '\\\\N','3_total_fee'] = test.loc[test['3_total_fee'] == '\\\\N','1_total_fee']*0.2 + test.loc[test['3_total_fee'] == '\\\\N','4_total_fee']*0.75\n",
    "#训练集， 直接清除所有确实值记录，这很少，不影响结果\n",
    "train = train[train['2_total_fee'] != '\\\\N']\n",
    "train = train[train['3_total_fee'] != '\\\\N']\n",
    "train = train[train['gender'] != '\\\\N']\n",
    "train = train[train['age'] != '\\\\N'].copy()\n",
    "\n",
    "train['2_total_fee'] = train['2_total_fee'].apply(float)\n",
    "train['3_total_fee'] = train['3_total_fee'].apply(float)\n",
    "train['gender'] = train['gender'].apply(int)\n",
    "train['age'] = train['age'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savePickle(target, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(target, f)\n",
    "def loadPickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "savePickle(train, \"./data/train.pkl\")\n",
    "savePickle(test, \"./data/test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将训练集与测试集合并，这样特征处理就可以一致\n",
    "test['current_service'] = -1\n",
    "data = train.append(test)\n",
    "data['2_total_fee'] = data['2_total_fee'].apply(float)\n",
    "data['3_total_fee'] = data['3_total_fee'].apply(float)\n",
    "data['gender'] = data['gender'].apply(int)\n",
    "data['age'] = data['age'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = ['complaint_level','contract_type','gender', 'is_mix_service', 'is_promise_low_consume',\n",
    "                     'many_over_bill','net_service','service_type']\n",
    "floatcontinous_features = ['1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee','former_complaint_fee',\n",
    "                           'last_month_traffic',       'local_caller_time', 'local_trafffic_month', \n",
    "                           'month_traffic', 'pay_num', 'service1_caller_time', 'service2_caller_time',]\n",
    "intcontinous_features = ['age','contract_time', 'former_complaint_num', 'online_time',  'pay_times']\n",
    "# intcontinous_features = ['contract_time', 'former_complaint_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1 = KMeans(n_clusters=40, random_state=0).fit(data[floatcontinous_features])\n",
    "kmeans2 = KMeans(n_clusters=12, random_state=0).fit(data[intcontinous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode = pd.DataFrame()\n",
    "for feature in category_features:\n",
    "    data_encode[feature] = np.array(data[feature]).astype(int).astype(np.object)\n",
    "\n",
    "for feature in floatcontinous_features:\n",
    "    v = np.array(data[feature]).astype(np.float32)\n",
    "    v = np.log(v - v.min() + 1) # 平移到 大于1 的正整数空间，然后取对数平滑。\n",
    "    v = v/v.max() #压缩到 0-1 之间。\n",
    "    data_encode[feature] = (v - v.mean())/v.std() # 取值为均值为0，方差为1的样本。\n",
    "    \n",
    "for feature in intcontinous_features:\n",
    "    v = np.array(data[feature]).astype(np.float32)\n",
    "    v = np.log(v - v.min() + 1) # 平移到 大于1 的正整数空间，然后取对数平滑。\n",
    "    v = v/v.max() #压缩到 0-1 之间。\n",
    "    data_encode[feature] = (v - v.mean())/v.std() # 取值为均值为0，方差为1的样本。\n",
    "    \n",
    "# 对于连续变量，进行聚类，进一步挖掘信息。\n",
    "\n",
    "data_encode['kmeans1'] = np.array(kmeans1.labels_).astype(np.object)\n",
    "data_encode['kmeans2'] = np.array(kmeans2.labels_).astype(np.object)\n",
    "data_encode = pd.get_dummies(data_encode)\n",
    "data_encode['user_id'] = np.array(data['user_id'])\n",
    "data_encode['current_service'] = np.array(data['current_service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_stats(tdf):\n",
    "#     dct = Counter(tdf)\n",
    "#     cn = len(tdf)\n",
    "#     for key in dct.keys():\n",
    "#         print(key, round(dct[key]/cn, 3))\n",
    "#     print(cn, end = \"\\n\\n\")\n",
    "    \n",
    "# odf = train['current_service']\n",
    "# print_stats(odf)\n",
    "# # tdf = train[train['former_complaint_fee'] > 0][train['former_complaint_fee'] < 100]['current_service']\n",
    "# tdf = train[train['3_total_fee'] < 0 ]['current_service']\n",
    "# print_stats(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "testData = data_encode[data_encode.current_service == -1]\n",
    "featureTest = testData.drop(['current_service', 'user_id'], axis = 1)\n",
    "TestResult = testData[['user_id']].copy()\n",
    "\n",
    "#train data \n",
    "trainData = data_encode[data_encode.current_service != -1]\n",
    "feature = trainData.drop(['current_service', 'user_id'],axis = 1)\n",
    "\n",
    "# label encode\n",
    "label = pd.DataFrame()\n",
    "label['cs'] = np.array(trainData['current_service']).astype(np.int).astype(np.object)\n",
    "label = pd.get_dummies(label)\n",
    "label_dict = getLabelDict(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_col = [*floatcontinous_features, *intcontinous_features]\n",
    "train_x_continuous = feature[continous_col]\n",
    "train_x_onehot = feature.drop(continous_col, axis = 1)\n",
    "test_x_continous = featureTest[continous_col]\n",
    "test_x_onehot = featureTest.drop(continous_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(train_x_continuous, \"./data/normaldata/train_x_continuous.pkl\")\n",
    "savePickle(train_x_onehot, \"./data/normaldata/train_x_onehot.pkl\")\n",
    "savePickle(test_x_continous, \"./data/normaldata/test_x_continous.pkl\")\n",
    "savePickle(test_x_onehot, \"./data/normaldata/test_x_onehot.pkl\")\n",
    "savePickle(feature, \"./data/normaldata/train_x.pkl\")\n",
    "savePickle(featureTest, \"./data/normaldata/test_x.pkl\")\n",
    "savePickle(label, \"./data/normaldata/train_y.pkl\")\n",
    "savePickle(label_dict, \"./data/normaldata/label_dict.pkl\")\n",
    "savePickle(TestResult, \"./data/normaldata/TestResult.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
